{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_copy import load_fabric_data, extract_label_grouping, extract_label_grouping, load_fabric_images\n",
    "import numpy as np\n",
    "from matplotlib import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = r\"C:/Users/Administrator/Desktop/PRML/Project/fabric_data/label_json/**/**.json\"\n",
    "\n",
    "fids, fdata = load_fabric_data(path)\n",
    "ftype1, ftype2 = extract_label_grouping(fdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Administrator/Desktop/PRML/Project/fabric_data/temp/**/**.jpg\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:/Users/Administrator/Desktop/PRML/Project/fabric_data/temp/\"\n",
    "labels, imgs = load_fabric_images(path, fids, fdata, ftype1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3371\n",
      "[[[130 130 128 155 147 171]\n",
      "  [139 137 138 151 150 168]\n",
      "  [147 145 148 146 154 167]\n",
      "  ...\n",
      "  [ 57  46  24  92  87  29]\n",
      "  [ 73  51  28  83  64  34]\n",
      "  [124  89  69  76  47  51]]\n",
      "\n",
      " [[139 141 140 162 153 174]\n",
      "  [143 144 146 157 155 168]\n",
      "  [148 148 150 151 155 166]\n",
      "  ...\n",
      "  [ 69  61  38 121 124  69]\n",
      "  [ 58  41  15 113 100  56]\n",
      "  [ 69  39  15  88  63  33]]\n",
      "\n",
      " [[143 147 150 160 149 166]\n",
      "  [145 149 152 156 153 162]\n",
      "  [150 151 156 153 156 161]\n",
      "  ...\n",
      "  [102 100  75 153 160 116]\n",
      "  [ 90  79  49 140 133  79]\n",
      "  [ 75  55  22 126 106  47]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 56  19  13  76  21  24]\n",
      "  [ 55  16  11  77  28  31]\n",
      "  [ 57  18  13  70  31  32]\n",
      "  ...\n",
      "  [208 213 219 210 213 206]\n",
      "  [208 218 220 222 223 228]\n",
      "  [200 210 211 216 213 234]]\n",
      "\n",
      " [[ 74  35  28 103  31  34]\n",
      "  [ 69  30  23 103  37  39]\n",
      "  [ 72  31  25  95  39  40]\n",
      "  ...\n",
      "  [191 200 209 212 212 212]\n",
      "  [220 231 237 209 209 221]\n",
      "  [196 210 213 213 210 237]]\n",
      "\n",
      " [[ 87  49  40 122  36  37]\n",
      "  [ 82  42  34 123  41  43]\n",
      "  [ 85  45  37 115  43  46]\n",
      "  ...\n",
      "  [185 193 204 214 212 223]\n",
      "  [195 208 216 215 212 233]\n",
      "  [193 208 215 217 216 248]]]\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))\n",
    "print(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 3371\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(imgs)\n",
    "print(\"Number of samples:\", n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 400, 6)\n"
     ]
    }
   ],
   "source": [
    "print(imgs[1230].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way of selecting categories\n",
    "from numpy import array\n",
    "\n",
    "myIndices = []\n",
    "def find_indices_four_cat(listOfLabel):\n",
    "    res = []\n",
    "    i = 0 \n",
    "    for i in range(0,len(listOfLabel)):\n",
    "        if (listOfLabel[i] == 1) or (listOfLabel[i]== 2) or (listOfLabel[i] == 5) or (listOfLabel[i] == 13): \n",
    "            res.append(i)\n",
    "    return res\n",
    "\n",
    "label_four_cat_indices = find_indices_four_cat(labels)\n",
    "\n",
    "# select the fours category out of the sample \n",
    "labels_four_cat = array(labels)[label_four_cat_indices]\n",
    "samples_four_cat = array(imgs)[label_four_cat_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1123\n"
     ]
    }
   ],
   "source": [
    "labels = labels_four_cat\n",
    "imgs = samples_four_cat\n",
    "\n",
    "print(len(imgs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Padding\n",
    "- https://blog.csdn.net/wuzqChom/article/details/74785643\n",
    "- https://stackoverflow.com/questions/47697622/cnn-image-resizing-vs-padding-keeping-aspect-ratio-or-not/49882055#49882055\n",
    "- https://stackoverflow.com/questions/43391205/add-padding-to-images-to-get-them-into-the-same-shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [cv2.resize(img,(200, 200)) for img in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images, train_labels, test_labels = train_test_split(imgs, labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#first split, split to the training and testing (we will futher split training later because we need validation set )\n",
    "train_images, test_images, train_labels, test_labels = np.array(train_images), np.array(test_images), np.array(train_labels), np.array(test_labels)\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n"
     ]
    }
   ],
   "source": [
    "train_images.shape\n",
    "print(len(test_labels))\n",
    "# note all the test labels are real images at this point. We are only going to generate fake data for the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "[[[[0.14117647 0.13333333 0.13333333 0.23529412 0.18431373 0.15686275]\n",
      "   [0.21960784 0.23529412 0.19607843 0.27843137 0.37647059 0.31372549]\n",
      "   [0.41568627 0.45490196 0.36078431 0.56862745 0.61176471 0.47058824]\n",
      "   ...\n",
      "   [0.5372549  0.52156863 0.38039216 0.60392157 0.58039216 0.44705882]\n",
      "   [0.56470588 0.5372549  0.38823529 0.60392157 0.58039216 0.43137255]\n",
      "   [0.58431373 0.54901961 0.39607843 0.61960784 0.58823529 0.42745098]]\n",
      "\n",
      "  [[0.14117647 0.1372549  0.14901961 0.18823529 0.18039216 0.16862745]\n",
      "   [0.3254902  0.33333333 0.30588235 0.42352941 0.49803922 0.45098039]\n",
      "   [0.48235294 0.49019608 0.41960784 0.60784314 0.64313725 0.5254902 ]\n",
      "   ...\n",
      "   [0.53333333 0.51372549 0.39215686 0.58823529 0.56078431 0.43921569]\n",
      "   [0.56470588 0.53333333 0.40784314 0.61176471 0.58039216 0.44313725]\n",
      "   [0.56862745 0.5254902  0.4        0.63529412 0.59607843 0.45490196]]\n",
      "\n",
      "  [[0.12941176 0.15294118 0.13333333 0.21960784 0.24313725 0.19607843]\n",
      "   [0.42352941 0.42352941 0.37254902 0.52941176 0.5372549  0.45098039]\n",
      "   [0.52941176 0.50980392 0.40784314 0.63921569 0.64313725 0.49803922]\n",
      "   ...\n",
      "   [0.54901961 0.53333333 0.4        0.59607843 0.57254902 0.44705882]\n",
      "   [0.57254902 0.54509804 0.40784314 0.61176471 0.58039216 0.43921569]\n",
      "   [0.57254902 0.53333333 0.39215686 0.62745098 0.58823529 0.44705882]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.09019608 0.09803922 0.10980392 0.12941176 0.1254902  0.10196078]\n",
      "   [0.10196078 0.09803922 0.12156863 0.11764706 0.12941176 0.10588235]\n",
      "   [0.10196078 0.09411765 0.12156863 0.12156863 0.13333333 0.10196078]\n",
      "   ...\n",
      "   [0.07843137 0.07843137 0.07843137 0.1254902  0.11764706 0.11764706]\n",
      "   [0.08627451 0.08627451 0.07843137 0.11372549 0.10980392 0.10588235]\n",
      "   [0.10196078 0.10196078 0.09411765 0.1254902  0.10980392 0.10980392]]\n",
      "\n",
      "  [[0.07843137 0.09411765 0.10196078 0.11764706 0.14509804 0.10980392]\n",
      "   [0.09411765 0.09019608 0.10980392 0.11764706 0.14117647 0.1254902 ]\n",
      "   [0.11372549 0.09803922 0.13333333 0.10980392 0.1254902  0.11764706]\n",
      "   ...\n",
      "   [0.08627451 0.08235294 0.0745098  0.12156863 0.11764706 0.11372549]\n",
      "   [0.08235294 0.08235294 0.0745098  0.11764706 0.10980392 0.10980392]\n",
      "   [0.09019608 0.08627451 0.07843137 0.13333333 0.11764706 0.10980392]]\n",
      "\n",
      "  [[0.09411765 0.09411765 0.06666667 0.1254902  0.12156863 0.13333333]\n",
      "   [0.10980392 0.09411765 0.07843137 0.1254902  0.11764706 0.1372549 ]\n",
      "   [0.10980392 0.10196078 0.10980392 0.12941176 0.12156863 0.13333333]\n",
      "   ...\n",
      "   [0.09019608 0.08627451 0.07843137 0.12941176 0.1254902  0.10196078]\n",
      "   [0.09019608 0.08627451 0.07843137 0.11764706 0.11372549 0.08627451]\n",
      "   [0.09411765 0.09019608 0.0745098  0.13333333 0.12156863 0.09803922]]]\n",
      "\n",
      "\n",
      " [[[0.08627451 0.05490196 0.10196078 0.09019608 0.09019608 0.11764706]\n",
      "   [0.09411765 0.07843137 0.09411765 0.11764706 0.05882353 0.1254902 ]\n",
      "   [0.14509804 0.1372549  0.14117647 0.2627451  0.21960784 0.21960784]\n",
      "   ...\n",
      "   [0.07058824 0.05490196 0.09411765 0.16470588 0.09019608 0.17647059]\n",
      "   [0.11764706 0.08627451 0.17254902 0.15294118 0.07843137 0.27843137]\n",
      "   [0.11764706 0.08235294 0.21568627 0.1372549  0.10196078 0.28235294]]\n",
      "\n",
      "  [[0.07843137 0.04705882 0.07843137 0.08627451 0.08235294 0.10980392]\n",
      "   [0.08235294 0.05882353 0.0745098  0.0745098  0.08627451 0.10980392]\n",
      "   [0.09019608 0.07058824 0.0745098  0.11764706 0.09019608 0.10588235]\n",
      "   ...\n",
      "   [0.08235294 0.06666667 0.08627451 0.11372549 0.09803922 0.13333333]\n",
      "   [0.11372549 0.07843137 0.1254902  0.1372549  0.10588235 0.23137255]\n",
      "   [0.12941176 0.08627451 0.18431373 0.12156863 0.09803922 0.2745098 ]]\n",
      "\n",
      "  [[0.0627451  0.03921569 0.05490196 0.12941176 0.08627451 0.09019608]\n",
      "   [0.07843137 0.05098039 0.07058824 0.10980392 0.10588235 0.14117647]\n",
      "   [0.10196078 0.0745098  0.08627451 0.08627451 0.0745098  0.09019608]\n",
      "   ...\n",
      "   [0.07843137 0.06666667 0.08235294 0.10980392 0.12941176 0.13333333]\n",
      "   [0.10588235 0.07058824 0.09411765 0.1254902  0.08235294 0.13333333]\n",
      "   [0.1372549  0.08627451 0.16470588 0.16862745 0.11372549 0.25098039]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.10980392 0.10588235 0.09411765 0.14117647 0.11764706 0.14901961]\n",
      "   [0.10196078 0.10980392 0.09803922 0.16470588 0.13333333 0.14901961]\n",
      "   [0.12156863 0.13333333 0.12941176 0.11764706 0.1254902  0.1254902 ]\n",
      "   ...\n",
      "   [0.59607843 0.60392157 0.43137255 0.65882353 0.61176471 0.50196078]\n",
      "   [0.60392157 0.60392157 0.41960784 0.71764706 0.6627451  0.57254902]\n",
      "   [0.58039216 0.61176471 0.41568627 0.75294118 0.66666667 0.57254902]]\n",
      "\n",
      "  [[0.10196078 0.09803922 0.09803922 0.1254902  0.12941176 0.15686275]\n",
      "   [0.10980392 0.10980392 0.09019608 0.14117647 0.14117647 0.14901961]\n",
      "   [0.09411765 0.10196078 0.09019608 0.11764706 0.13333333 0.14901961]\n",
      "   ...\n",
      "   [0.54509804 0.54509804 0.40392157 0.68235294 0.65098039 0.56078431]\n",
      "   [0.60392157 0.60392157 0.44313725 0.72156863 0.68235294 0.59215686]\n",
      "   [0.57647059 0.61176471 0.43137255 0.76078431 0.69803922 0.59215686]]\n",
      "\n",
      "  [[0.11372549 0.10980392 0.10196078 0.12941176 0.12941176 0.15294118]\n",
      "   [0.11372549 0.10980392 0.08235294 0.1254902  0.13333333 0.11764706]\n",
      "   [0.11372549 0.11764706 0.09411765 0.12156863 0.13333333 0.12156863]\n",
      "   ...\n",
      "   [0.30196078 0.29803922 0.18039216 0.60784314 0.54901961 0.46666667]\n",
      "   [0.56470588 0.55686275 0.41568627 0.70196078 0.65882353 0.57254902]\n",
      "   [0.54117647 0.57647059 0.40784314 0.74117647 0.68627451 0.58039216]]]\n",
      "\n",
      "\n",
      " [[[0.0627451  0.05490196 0.05490196 0.0627451  0.04705882 0.05882353]\n",
      "   [0.14509804 0.10196078 0.11764706 0.25490196 0.15686275 0.21176471]\n",
      "   [0.38431373 0.38431373 0.39215686 0.42352941 0.44313725 0.46666667]\n",
      "   ...\n",
      "   [0.03921569 0.03137255 0.04313725 0.07058824 0.05098039 0.05490196]\n",
      "   [0.0627451  0.04705882 0.0627451  0.05490196 0.03529412 0.03921569]\n",
      "   [0.0627451  0.04705882 0.0627451  0.0627451  0.05882353 0.0627451 ]]\n",
      "\n",
      "  [[0.07058824 0.03137255 0.05098039 0.0627451  0.07058824 0.07058824]\n",
      "   [0.23529412 0.17254902 0.20392157 0.3372549  0.21176471 0.2745098 ]\n",
      "   [0.55686275 0.5372549  0.56470588 0.59607843 0.56470588 0.61176471]\n",
      "   ...\n",
      "   [0.04705882 0.03921569 0.05098039 0.07058824 0.04705882 0.05490196]\n",
      "   [0.06666667 0.04705882 0.0627451  0.07843137 0.05490196 0.0627451 ]\n",
      "   [0.05882353 0.03921569 0.05490196 0.05098039 0.04705882 0.05098039]]\n",
      "\n",
      "  [[0.07843137 0.02352941 0.05098039 0.06666667 0.04705882 0.05882353]\n",
      "   [0.24705882 0.16470588 0.21176471 0.35294118 0.21960784 0.28627451]\n",
      "   [0.54901961 0.51372549 0.56470588 0.61568627 0.57647059 0.63529412]\n",
      "   ...\n",
      "   [0.05490196 0.03529412 0.05098039 0.05490196 0.02352941 0.03137255]\n",
      "   [0.07058824 0.05098039 0.06666667 0.07058824 0.04313725 0.05490196]\n",
      "   [0.06666667 0.04705882 0.0627451  0.06666667 0.05490196 0.05882353]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.08627451 0.05490196 0.05098039 0.04313725 0.03921569 0.03137255]\n",
      "   [0.06666667 0.05098039 0.05098039 0.0627451  0.03137255 0.03529412]\n",
      "   [0.07843137 0.05490196 0.07058824 0.11372549 0.06666667 0.08235294]\n",
      "   ...\n",
      "   [0.10980392 0.02352941 0.02352941 0.0745098  0.05490196 0.04313725]\n",
      "   [0.11372549 0.06666667 0.07058824 0.07843137 0.05490196 0.0627451 ]\n",
      "   [0.05490196 0.04313725 0.05098039 0.05490196 0.04705882 0.04313725]]\n",
      "\n",
      "  [[0.0745098  0.03921569 0.03137255 0.04705882 0.03921569 0.04313725]\n",
      "   [0.08627451 0.07058824 0.07058824 0.08627451 0.05490196 0.06666667]\n",
      "   [0.14117647 0.11764706 0.13333333 0.18823529 0.14117647 0.15686275]\n",
      "   ...\n",
      "   [0.04705882 0.02352941 0.02352941 0.07058824 0.0627451  0.08235294]\n",
      "   [0.06666667 0.04705882 0.05882353 0.05882353 0.05490196 0.0627451 ]\n",
      "   [0.06666667 0.05490196 0.0745098  0.0745098  0.04313725 0.04313725]]\n",
      "\n",
      "  [[0.08235294 0.04705882 0.04313725 0.06666667 0.03921569 0.05882353]\n",
      "   [0.0745098  0.05882353 0.05882353 0.07058824 0.05490196 0.07058824]\n",
      "   [0.18823529 0.16470588 0.18039216 0.10196078 0.07058824 0.08627451]\n",
      "   ...\n",
      "   [0.04313725 0.03921569 0.03137255 0.0627451  0.05098039 0.09019608]\n",
      "   [0.05490196 0.04705882 0.05490196 0.08627451 0.05098039 0.06666667]\n",
      "   [0.04705882 0.03921569 0.05882353 0.0745098  0.03921569 0.03137255]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.56078431 0.48627451 0.35686275 0.69019608 0.57254902 0.41568627]\n",
      "   [0.54509804 0.4627451  0.3372549  0.6745098  0.56078431 0.40784314]\n",
      "   [0.56078431 0.47058824 0.34509804 0.65490196 0.54901961 0.4       ]\n",
      "   ...\n",
      "   [0.07058824 0.18039216 0.19607843 0.07058824 0.19607843 0.19215686]\n",
      "   [0.05882353 0.17254902 0.18039216 0.0627451  0.19607843 0.19215686]\n",
      "   [0.04313725 0.16862745 0.16862745 0.08627451 0.22745098 0.21960784]]\n",
      "\n",
      "  [[0.54901961 0.47843137 0.35294118 0.71764706 0.60784314 0.44705882]\n",
      "   [0.54117647 0.4627451  0.34117647 0.6745098  0.56470588 0.41176471]\n",
      "   [0.56862745 0.48627451 0.36470588 0.68235294 0.58039216 0.42745098]\n",
      "   ...\n",
      "   [0.0745098  0.18431373 0.19215686 0.0627451  0.2        0.2       ]\n",
      "   [0.05098039 0.16470588 0.16470588 0.05882353 0.20392157 0.19607843]\n",
      "   [0.05098039 0.17647059 0.16470588 0.06666667 0.21960784 0.20784314]]\n",
      "\n",
      "  [[0.54901961 0.48627451 0.36078431 0.68235294 0.57647059 0.40784314]\n",
      "   [0.50980392 0.44313725 0.31372549 0.65098039 0.54901961 0.38823529]\n",
      "   [0.51764706 0.43921569 0.31372549 0.65098039 0.55686275 0.39607843]\n",
      "   ...\n",
      "   [0.07843137 0.19215686 0.18431373 0.05882353 0.20392157 0.20392157]\n",
      "   [0.05882353 0.17647059 0.16078431 0.05490196 0.20784314 0.20392157]\n",
      "   [0.04313725 0.16862745 0.14901961 0.03529412 0.19607843 0.18039216]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.57254902 0.49411765 0.37254902 0.62745098 0.53333333 0.41568627]\n",
      "   [0.55686275 0.47058824 0.36078431 0.6627451  0.56862745 0.43921569]\n",
      "   [0.54901961 0.46666667 0.35294118 0.67058824 0.58039216 0.43529412]\n",
      "   ...\n",
      "   [0.83137255 0.83137255 0.7372549  0.8745098  0.65882353 0.07058824]\n",
      "   [0.82745098 0.85098039 0.81176471 0.86666667 0.72941176 0.2627451 ]\n",
      "   [0.81960784 0.85490196 0.81568627 0.8627451  0.8627451  0.65098039]]\n",
      "\n",
      "  [[0.58039216 0.49803922 0.36862745 0.62745098 0.53333333 0.41568627]\n",
      "   [0.58039216 0.49411765 0.37254902 0.63921569 0.54901961 0.40784314]\n",
      "   [0.59215686 0.50588235 0.38431373 0.65098039 0.55686275 0.40392157]\n",
      "   ...\n",
      "   [0.8        0.82352941 0.77647059 0.84705882 0.65882353 0.14117647]\n",
      "   [0.82352941 0.84313725 0.81176471 0.83529412 0.78431373 0.47843137]\n",
      "   [0.82352941 0.84705882 0.81568627 0.82352941 0.8627451  0.78431373]]\n",
      "\n",
      "  [[0.6        0.51372549 0.36862745 0.62745098 0.55294118 0.41960784]\n",
      "   [0.61176471 0.5254902  0.38823529 0.63529412 0.55686275 0.40784314]\n",
      "   [0.59215686 0.50196078 0.37254902 0.65882353 0.58039216 0.41176471]\n",
      "   ...\n",
      "   [0.80784314 0.85490196 0.81960784 0.85490196 0.68235294 0.2745098 ]\n",
      "   [0.83529412 0.85098039 0.82745098 0.82745098 0.83921569 0.6745098 ]\n",
      "   [0.83921569 0.84705882 0.82745098 0.79607843 0.84313725 0.84313725]]]\n",
      "\n",
      "\n",
      " [[[0.8627451  0.87843137 0.92156863 0.91372549 0.9254902  0.95294118]\n",
      "   [0.83921569 0.85490196 0.89803922 0.90196078 0.9254902  0.95294118]\n",
      "   [0.81568627 0.82745098 0.87058824 0.87843137 0.92156863 0.95686275]\n",
      "   ...\n",
      "   [0.9254902  0.92941176 0.96470588 0.85490196 0.8745098  0.9372549 ]\n",
      "   [0.90588235 0.90196078 0.9372549  0.90980392 0.91372549 0.95294118]\n",
      "   [0.90980392 0.90588235 0.92941176 0.83137255 0.85098039 0.89411765]]\n",
      "\n",
      "  [[0.85490196 0.88235294 0.91764706 0.87843137 0.89411765 0.9254902 ]\n",
      "   [0.84705882 0.8627451  0.90196078 0.90980392 0.9254902  0.96470588]\n",
      "   [0.8627451  0.87843137 0.91372549 0.88235294 0.89411765 0.9372549 ]\n",
      "   ...\n",
      "   [0.87843137 0.88627451 0.91764706 0.85882353 0.87843137 0.92156863]\n",
      "   [0.91764706 0.91372549 0.94509804 0.90196078 0.92156863 0.94509804]\n",
      "   [0.92156863 0.91764706 0.94117647 0.88627451 0.90980392 0.94117647]]\n",
      "\n",
      "  [[0.82352941 0.85098039 0.87843137 0.87843137 0.90196078 0.9254902 ]\n",
      "   [0.78431373 0.80784314 0.83137255 0.88235294 0.87843137 0.93333333]\n",
      "   [0.84313725 0.8627451  0.88627451 0.9372549  0.94901961 0.97254902]\n",
      "   ...\n",
      "   [0.92156863 0.92941176 0.94901961 0.80392157 0.83921569 0.87058824]\n",
      "   [0.89019608 0.89411765 0.91372549 0.89019608 0.88627451 0.90588235]\n",
      "   [0.92941176 0.9254902  0.94901961 0.85490196 0.87058824 0.89411765]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.98823529 0.99607843 0.99607843 0.98431373 0.99607843 1.        ]\n",
      "   [0.91372549 0.9254902  0.93333333 0.90196078 0.9254902  0.96078431]\n",
      "   [0.82352941 0.83921569 0.87058824 0.8745098  0.90588235 0.94901961]\n",
      "   ...\n",
      "   [0.85490196 0.87058824 0.87843137 0.89411765 0.89019608 0.9254902 ]\n",
      "   [0.86666667 0.87843137 0.88627451 0.93333333 0.9254902  0.94901961]\n",
      "   [0.88627451 0.89019608 0.90980392 0.87058824 0.86666667 0.88627451]]\n",
      "\n",
      "  [[0.99215686 1.         0.99607843 0.98431373 0.99607843 0.99215686]\n",
      "   [0.97254902 0.98823529 0.99215686 0.94509804 0.96470588 0.98823529]\n",
      "   [0.85490196 0.8745098  0.89019608 0.82352941 0.85490196 0.89019608]\n",
      "   ...\n",
      "   [0.96470588 0.98039216 0.98039216 0.92941176 0.92941176 0.94509804]\n",
      "   [0.97254902 0.98823529 0.99215686 0.90980392 0.91372549 0.93333333]\n",
      "   [0.98039216 0.98431373 0.99607843 0.93333333 0.94509804 0.96862745]]\n",
      "\n",
      "  [[0.98823529 0.99607843 0.99607843 0.99215686 1.         0.98823529]\n",
      "   [0.98431373 1.         1.         0.97254902 0.98823529 0.99215686]\n",
      "   [0.98039216 1.         1.         0.89019608 0.91764706 0.9372549 ]\n",
      "   ...\n",
      "   [0.98039216 0.99607843 0.99215686 0.98823529 0.99607843 0.98823529]\n",
      "   [0.94509804 0.96078431 0.96470588 0.97254902 0.99215686 0.98823529]\n",
      "   [0.96862745 0.97647059 0.98823529 0.89411765 0.93333333 0.9254902 ]]]\n",
      "\n",
      "\n",
      " [[[0.0627451  0.03921569 0.0627451  0.05098039 0.04313725 0.04705882]\n",
      "   [0.05882353 0.03921569 0.03137255 0.07058824 0.05490196 0.05882353]\n",
      "   [0.11372549 0.09411765 0.07843137 0.09019608 0.06666667 0.07843137]\n",
      "   ...\n",
      "   [0.05882353 0.05098039 0.04313725 0.07843137 0.05882353 0.0745098 ]\n",
      "   [0.05490196 0.05098039 0.04313725 0.09411765 0.07843137 0.09411765]\n",
      "   [0.05490196 0.05098039 0.04313725 0.0627451  0.03921569 0.05490196]]\n",
      "\n",
      "  [[0.0745098  0.05490196 0.07058824 0.05098039 0.04705882 0.04313725]\n",
      "   [0.05490196 0.03529412 0.03529412 0.0627451  0.04705882 0.04705882]\n",
      "   [0.07058824 0.05490196 0.04705882 0.07058824 0.04705882 0.05490196]\n",
      "   ...\n",
      "   [0.07058824 0.05882353 0.05490196 0.05490196 0.03529412 0.05098039]\n",
      "   [0.07843137 0.0745098  0.06666667 0.0627451  0.04313725 0.05882353]\n",
      "   [0.05882353 0.05490196 0.04705882 0.05490196 0.03137255 0.04705882]]\n",
      "\n",
      "  [[0.05490196 0.03529412 0.04705882 0.05882353 0.05490196 0.04705882]\n",
      "   [0.05882353 0.04313725 0.04705882 0.04705882 0.03137255 0.03137255]\n",
      "   [0.05882353 0.04313725 0.04313725 0.06666667 0.04313725 0.04313725]\n",
      "   ...\n",
      "   [0.07843137 0.0627451  0.05490196 0.09411765 0.08235294 0.09411765]\n",
      "   [0.0627451  0.04705882 0.04313725 0.09019608 0.07058824 0.08627451]\n",
      "   [0.07058824 0.0627451  0.05490196 0.06666667 0.04705882 0.0627451 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.05882353 0.03921569 0.0627451  0.09411765 0.0745098  0.0745098 ]\n",
      "   [0.07058824 0.05490196 0.07058824 0.07058824 0.03921569 0.05098039]\n",
      "   [0.16470588 0.14509804 0.16078431 0.1372549  0.09803922 0.10980392]\n",
      "   ...\n",
      "   [0.0745098  0.05882353 0.05882353 0.07058824 0.0627451  0.0745098 ]\n",
      "   [0.0627451  0.04705882 0.04705882 0.04705882 0.03529412 0.04705882]\n",
      "   [0.05882353 0.04313725 0.04313725 0.03921569 0.02745098 0.03921569]]\n",
      "\n",
      "  [[0.05490196 0.02352941 0.05490196 0.09019608 0.0627451  0.0627451 ]\n",
      "   [0.06666667 0.04705882 0.06666667 0.09411765 0.05882353 0.06666667]\n",
      "   [0.16862745 0.14901961 0.16470588 0.22745098 0.18039216 0.19607843]\n",
      "   ...\n",
      "   [0.07058824 0.05490196 0.05098039 0.06666667 0.05098039 0.06666667]\n",
      "   [0.0745098  0.05882353 0.05490196 0.09411765 0.07058824 0.08627451]\n",
      "   [0.05882353 0.04313725 0.03921569 0.0745098  0.05490196 0.07058824]]\n",
      "\n",
      "  [[0.0627451  0.03529412 0.0627451  0.05882353 0.03529412 0.02745098]\n",
      "   [0.05098039 0.03137255 0.04705882 0.06666667 0.03137255 0.03921569]\n",
      "   [0.16862745 0.14901961 0.16470588 0.25098039 0.19607843 0.21176471]\n",
      "   ...\n",
      "   [0.08235294 0.06666667 0.05490196 0.0627451  0.04313725 0.05882353]\n",
      "   [0.07843137 0.0627451  0.05098039 0.0745098  0.05098039 0.06666667]\n",
      "   [0.08627451 0.07058824 0.05882353 0.08627451 0.0627451  0.07843137]]]]\n"
     ]
    }
   ],
   "source": [
    "# subset all the 5s \n",
    "def find_indices_5(listOfLabel):\n",
    "    res = []\n",
    "    i = 0 \n",
    "    for i in range(0,len(listOfLabel)):\n",
    "        if (listOfLabel[i] == 5): \n",
    "            res.append(i)\n",
    "    return res\n",
    "\n",
    "label_five = find_indices_5(train_labels)\n",
    "print(len(label_five))\n",
    "\n",
    "train_is_five = array(train_images)[label_five]\n",
    "\n",
    "# the is the training data that has labelled as \"5\"\n",
    "print(train_is_five)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate fake data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augementation. Because category five has only 13 samples. We decide to rotate them and flip them and etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.05490196 0.05098039 0.04313725 0.0627451  0.03921569 0.05490196]\n",
      "   [0.05882353 0.05490196 0.04705882 0.05490196 0.03137255 0.04705882]\n",
      "   [0.07058824 0.0627451  0.05490196 0.06666667 0.04705882 0.0627451 ]\n",
      "   ...\n",
      "   [0.05882353 0.04313725 0.04313725 0.03921569 0.02745098 0.03921569]\n",
      "   [0.05882353 0.04313725 0.03921569 0.0745098  0.05490196 0.07058824]\n",
      "   [0.08627451 0.07058824 0.05882353 0.08627451 0.0627451  0.07843137]]\n",
      "\n",
      "  [[0.05490196 0.05098039 0.04313725 0.09411765 0.07843137 0.09411765]\n",
      "   [0.07843137 0.0745098  0.06666667 0.0627451  0.04313725 0.05882353]\n",
      "   [0.0627451  0.04705882 0.04313725 0.09019608 0.07058824 0.08627451]\n",
      "   ...\n",
      "   [0.0627451  0.04705882 0.04705882 0.04705882 0.03529412 0.04705882]\n",
      "   [0.0745098  0.05882353 0.05490196 0.09411765 0.07058824 0.08627451]\n",
      "   [0.07843137 0.0627451  0.05098039 0.0745098  0.05098039 0.06666667]]\n",
      "\n",
      "  [[0.05882353 0.05098039 0.04313725 0.07843137 0.05882353 0.0745098 ]\n",
      "   [0.07058824 0.05882353 0.05490196 0.05490196 0.03529412 0.05098039]\n",
      "   [0.07843137 0.0627451  0.05490196 0.09411765 0.08235294 0.09411765]\n",
      "   ...\n",
      "   [0.0745098  0.05882353 0.05882353 0.07058824 0.0627451  0.0745098 ]\n",
      "   [0.07058824 0.05490196 0.05098039 0.06666667 0.05098039 0.06666667]\n",
      "   [0.08235294 0.06666667 0.05490196 0.0627451  0.04313725 0.05882353]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.11372549 0.09411765 0.07843137 0.09019608 0.06666667 0.07843137]\n",
      "   [0.07058824 0.05490196 0.04705882 0.07058824 0.04705882 0.05490196]\n",
      "   [0.05882353 0.04313725 0.04313725 0.06666667 0.04313725 0.04313725]\n",
      "   ...\n",
      "   [0.16470588 0.14509804 0.16078431 0.1372549  0.09803922 0.10980392]\n",
      "   [0.16862745 0.14901961 0.16470588 0.22745098 0.18039216 0.19607843]\n",
      "   [0.16862745 0.14901961 0.16470588 0.25098039 0.19607843 0.21176471]]\n",
      "\n",
      "  [[0.05882353 0.03921569 0.03137255 0.07058824 0.05490196 0.05882353]\n",
      "   [0.05490196 0.03529412 0.03529412 0.0627451  0.04705882 0.04705882]\n",
      "   [0.05882353 0.04313725 0.04705882 0.04705882 0.03137255 0.03137255]\n",
      "   ...\n",
      "   [0.07058824 0.05490196 0.07058824 0.07058824 0.03921569 0.05098039]\n",
      "   [0.06666667 0.04705882 0.06666667 0.09411765 0.05882353 0.06666667]\n",
      "   [0.05098039 0.03137255 0.04705882 0.06666667 0.03137255 0.03921569]]\n",
      "\n",
      "  [[0.0627451  0.03921569 0.0627451  0.05098039 0.04313725 0.04705882]\n",
      "   [0.0745098  0.05490196 0.07058824 0.05098039 0.04705882 0.04313725]\n",
      "   [0.05490196 0.03529412 0.04705882 0.05882353 0.05490196 0.04705882]\n",
      "   ...\n",
      "   [0.05882353 0.03921569 0.0627451  0.09411765 0.0745098  0.0745098 ]\n",
      "   [0.05490196 0.02352941 0.05490196 0.09019608 0.0627451  0.0627451 ]\n",
      "   [0.0627451  0.03529412 0.0627451  0.05882353 0.03529412 0.02745098]]]\n",
      "\n",
      "\n",
      " [[[0.0627451  0.03529412 0.0627451  0.05882353 0.03529412 0.02745098]\n",
      "   [0.05490196 0.02352941 0.05490196 0.09019608 0.0627451  0.0627451 ]\n",
      "   [0.05882353 0.03921569 0.0627451  0.09411765 0.0745098  0.0745098 ]\n",
      "   ...\n",
      "   [0.05490196 0.03529412 0.04705882 0.05882353 0.05490196 0.04705882]\n",
      "   [0.0745098  0.05490196 0.07058824 0.05098039 0.04705882 0.04313725]\n",
      "   [0.0627451  0.03921569 0.0627451  0.05098039 0.04313725 0.04705882]]\n",
      "\n",
      "  [[0.05098039 0.03137255 0.04705882 0.06666667 0.03137255 0.03921569]\n",
      "   [0.06666667 0.04705882 0.06666667 0.09411765 0.05882353 0.06666667]\n",
      "   [0.07058824 0.05490196 0.07058824 0.07058824 0.03921569 0.05098039]\n",
      "   ...\n",
      "   [0.05882353 0.04313725 0.04705882 0.04705882 0.03137255 0.03137255]\n",
      "   [0.05490196 0.03529412 0.03529412 0.0627451  0.04705882 0.04705882]\n",
      "   [0.05882353 0.03921569 0.03137255 0.07058824 0.05490196 0.05882353]]\n",
      "\n",
      "  [[0.16862745 0.14901961 0.16470588 0.25098039 0.19607843 0.21176471]\n",
      "   [0.16862745 0.14901961 0.16470588 0.22745098 0.18039216 0.19607843]\n",
      "   [0.16470588 0.14509804 0.16078431 0.1372549  0.09803922 0.10980392]\n",
      "   ...\n",
      "   [0.05882353 0.04313725 0.04313725 0.06666667 0.04313725 0.04313725]\n",
      "   [0.07058824 0.05490196 0.04705882 0.07058824 0.04705882 0.05490196]\n",
      "   [0.11372549 0.09411765 0.07843137 0.09019608 0.06666667 0.07843137]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.08235294 0.06666667 0.05490196 0.0627451  0.04313725 0.05882353]\n",
      "   [0.07058824 0.05490196 0.05098039 0.06666667 0.05098039 0.06666667]\n",
      "   [0.0745098  0.05882353 0.05882353 0.07058824 0.0627451  0.0745098 ]\n",
      "   ...\n",
      "   [0.07843137 0.0627451  0.05490196 0.09411765 0.08235294 0.09411765]\n",
      "   [0.07058824 0.05882353 0.05490196 0.05490196 0.03529412 0.05098039]\n",
      "   [0.05882353 0.05098039 0.04313725 0.07843137 0.05882353 0.0745098 ]]\n",
      "\n",
      "  [[0.07843137 0.0627451  0.05098039 0.0745098  0.05098039 0.06666667]\n",
      "   [0.0745098  0.05882353 0.05490196 0.09411765 0.07058824 0.08627451]\n",
      "   [0.0627451  0.04705882 0.04705882 0.04705882 0.03529412 0.04705882]\n",
      "   ...\n",
      "   [0.0627451  0.04705882 0.04313725 0.09019608 0.07058824 0.08627451]\n",
      "   [0.07843137 0.0745098  0.06666667 0.0627451  0.04313725 0.05882353]\n",
      "   [0.05490196 0.05098039 0.04313725 0.09411765 0.07843137 0.09411765]]\n",
      "\n",
      "  [[0.08627451 0.07058824 0.05882353 0.08627451 0.0627451  0.07843137]\n",
      "   [0.05882353 0.04313725 0.03921569 0.0745098  0.05490196 0.07058824]\n",
      "   [0.05882353 0.04313725 0.04313725 0.03921569 0.02745098 0.03921569]\n",
      "   ...\n",
      "   [0.07058824 0.0627451  0.05490196 0.06666667 0.04705882 0.0627451 ]\n",
      "   [0.05882353 0.05490196 0.04705882 0.05490196 0.03137255 0.04705882]\n",
      "   [0.05490196 0.05098039 0.04313725 0.0627451  0.03921569 0.05490196]]]\n",
      "\n",
      "\n",
      " [[[0.08627451 0.07058824 0.05882353 0.08627451 0.0627451  0.07843137]\n",
      "   [0.07843137 0.0627451  0.05098039 0.0745098  0.05098039 0.06666667]\n",
      "   [0.08235294 0.06666667 0.05490196 0.0627451  0.04313725 0.05882353]\n",
      "   ...\n",
      "   [0.16862745 0.14901961 0.16470588 0.25098039 0.19607843 0.21176471]\n",
      "   [0.05098039 0.03137255 0.04705882 0.06666667 0.03137255 0.03921569]\n",
      "   [0.0627451  0.03529412 0.0627451  0.05882353 0.03529412 0.02745098]]\n",
      "\n",
      "  [[0.05882353 0.04313725 0.03921569 0.0745098  0.05490196 0.07058824]\n",
      "   [0.0745098  0.05882353 0.05490196 0.09411765 0.07058824 0.08627451]\n",
      "   [0.07058824 0.05490196 0.05098039 0.06666667 0.05098039 0.06666667]\n",
      "   ...\n",
      "   [0.16862745 0.14901961 0.16470588 0.22745098 0.18039216 0.19607843]\n",
      "   [0.06666667 0.04705882 0.06666667 0.09411765 0.05882353 0.06666667]\n",
      "   [0.05490196 0.02352941 0.05490196 0.09019608 0.0627451  0.0627451 ]]\n",
      "\n",
      "  [[0.05882353 0.04313725 0.04313725 0.03921569 0.02745098 0.03921569]\n",
      "   [0.0627451  0.04705882 0.04705882 0.04705882 0.03529412 0.04705882]\n",
      "   [0.0745098  0.05882353 0.05882353 0.07058824 0.0627451  0.0745098 ]\n",
      "   ...\n",
      "   [0.16470588 0.14509804 0.16078431 0.1372549  0.09803922 0.10980392]\n",
      "   [0.07058824 0.05490196 0.07058824 0.07058824 0.03921569 0.05098039]\n",
      "   [0.05882353 0.03921569 0.0627451  0.09411765 0.0745098  0.0745098 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.07058824 0.0627451  0.05490196 0.06666667 0.04705882 0.0627451 ]\n",
      "   [0.0627451  0.04705882 0.04313725 0.09019608 0.07058824 0.08627451]\n",
      "   [0.07843137 0.0627451  0.05490196 0.09411765 0.08235294 0.09411765]\n",
      "   ...\n",
      "   [0.05882353 0.04313725 0.04313725 0.06666667 0.04313725 0.04313725]\n",
      "   [0.05882353 0.04313725 0.04705882 0.04705882 0.03137255 0.03137255]\n",
      "   [0.05490196 0.03529412 0.04705882 0.05882353 0.05490196 0.04705882]]\n",
      "\n",
      "  [[0.05882353 0.05490196 0.04705882 0.05490196 0.03137255 0.04705882]\n",
      "   [0.07843137 0.0745098  0.06666667 0.0627451  0.04313725 0.05882353]\n",
      "   [0.07058824 0.05882353 0.05490196 0.05490196 0.03529412 0.05098039]\n",
      "   ...\n",
      "   [0.07058824 0.05490196 0.04705882 0.07058824 0.04705882 0.05490196]\n",
      "   [0.05490196 0.03529412 0.03529412 0.0627451  0.04705882 0.04705882]\n",
      "   [0.0745098  0.05490196 0.07058824 0.05098039 0.04705882 0.04313725]]\n",
      "\n",
      "  [[0.05490196 0.05098039 0.04313725 0.0627451  0.03921569 0.05490196]\n",
      "   [0.05490196 0.05098039 0.04313725 0.09411765 0.07843137 0.09411765]\n",
      "   [0.05882353 0.05098039 0.04313725 0.07843137 0.05882353 0.0745098 ]\n",
      "   ...\n",
      "   [0.11372549 0.09411765 0.07843137 0.09019608 0.06666667 0.07843137]\n",
      "   [0.05882353 0.03921569 0.03137255 0.07058824 0.05490196 0.05882353]\n",
      "   [0.0627451  0.03921569 0.0627451  0.05098039 0.04313725 0.04705882]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.08627451 0.07058824 0.05882353 0.08627451 0.0627451  0.07843137]\n",
      "   [0.05882353 0.04313725 0.03921569 0.0745098  0.05490196 0.07058824]\n",
      "   [0.05882353 0.04313725 0.04313725 0.03921569 0.02745098 0.03921569]\n",
      "   ...\n",
      "   [0.07058824 0.0627451  0.05490196 0.06666667 0.04705882 0.0627451 ]\n",
      "   [0.05882353 0.05490196 0.04705882 0.05490196 0.03137255 0.04705882]\n",
      "   [0.05490196 0.05098039 0.04313725 0.0627451  0.03921569 0.05490196]]\n",
      "\n",
      "  [[0.07843137 0.0627451  0.05098039 0.0745098  0.05098039 0.06666667]\n",
      "   [0.0745098  0.05882353 0.05490196 0.09411765 0.07058824 0.08627451]\n",
      "   [0.0627451  0.04705882 0.04705882 0.04705882 0.03529412 0.04705882]\n",
      "   ...\n",
      "   [0.0627451  0.04705882 0.04313725 0.09019608 0.07058824 0.08627451]\n",
      "   [0.07843137 0.0745098  0.06666667 0.0627451  0.04313725 0.05882353]\n",
      "   [0.05490196 0.05098039 0.04313725 0.09411765 0.07843137 0.09411765]]\n",
      "\n",
      "  [[0.08235294 0.06666667 0.05490196 0.0627451  0.04313725 0.05882353]\n",
      "   [0.07058824 0.05490196 0.05098039 0.06666667 0.05098039 0.06666667]\n",
      "   [0.0745098  0.05882353 0.05882353 0.07058824 0.0627451  0.0745098 ]\n",
      "   ...\n",
      "   [0.07843137 0.0627451  0.05490196 0.09411765 0.08235294 0.09411765]\n",
      "   [0.07058824 0.05882353 0.05490196 0.05490196 0.03529412 0.05098039]\n",
      "   [0.05882353 0.05098039 0.04313725 0.07843137 0.05882353 0.0745098 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.16862745 0.14901961 0.16470588 0.25098039 0.19607843 0.21176471]\n",
      "   [0.16862745 0.14901961 0.16470588 0.22745098 0.18039216 0.19607843]\n",
      "   [0.16470588 0.14509804 0.16078431 0.1372549  0.09803922 0.10980392]\n",
      "   ...\n",
      "   [0.05882353 0.04313725 0.04313725 0.06666667 0.04313725 0.04313725]\n",
      "   [0.07058824 0.05490196 0.04705882 0.07058824 0.04705882 0.05490196]\n",
      "   [0.11372549 0.09411765 0.07843137 0.09019608 0.06666667 0.07843137]]\n",
      "\n",
      "  [[0.05098039 0.03137255 0.04705882 0.06666667 0.03137255 0.03921569]\n",
      "   [0.06666667 0.04705882 0.06666667 0.09411765 0.05882353 0.06666667]\n",
      "   [0.07058824 0.05490196 0.07058824 0.07058824 0.03921569 0.05098039]\n",
      "   ...\n",
      "   [0.05882353 0.04313725 0.04705882 0.04705882 0.03137255 0.03137255]\n",
      "   [0.05490196 0.03529412 0.03529412 0.0627451  0.04705882 0.04705882]\n",
      "   [0.05882353 0.03921569 0.03137255 0.07058824 0.05490196 0.05882353]]\n",
      "\n",
      "  [[0.0627451  0.03529412 0.0627451  0.05882353 0.03529412 0.02745098]\n",
      "   [0.05490196 0.02352941 0.05490196 0.09019608 0.0627451  0.0627451 ]\n",
      "   [0.05882353 0.03921569 0.0627451  0.09411765 0.0745098  0.0745098 ]\n",
      "   ...\n",
      "   [0.05490196 0.03529412 0.04705882 0.05882353 0.05490196 0.04705882]\n",
      "   [0.0745098  0.05490196 0.07058824 0.05098039 0.04705882 0.04313725]\n",
      "   [0.0627451  0.03921569 0.0627451  0.05098039 0.04313725 0.04705882]]]\n",
      "\n",
      "\n",
      " [[[0.05490196 0.05098039 0.04313725 0.0627451  0.03921569 0.05490196]\n",
      "   [0.05490196 0.05098039 0.04313725 0.09411765 0.07843137 0.09411765]\n",
      "   [0.05882353 0.05098039 0.04313725 0.07843137 0.05882353 0.0745098 ]\n",
      "   ...\n",
      "   [0.11372549 0.09411765 0.07843137 0.09019608 0.06666667 0.07843137]\n",
      "   [0.05882353 0.03921569 0.03137255 0.07058824 0.05490196 0.05882353]\n",
      "   [0.0627451  0.03921569 0.0627451  0.05098039 0.04313725 0.04705882]]\n",
      "\n",
      "  [[0.05882353 0.05490196 0.04705882 0.05490196 0.03137255 0.04705882]\n",
      "   [0.07843137 0.0745098  0.06666667 0.0627451  0.04313725 0.05882353]\n",
      "   [0.07058824 0.05882353 0.05490196 0.05490196 0.03529412 0.05098039]\n",
      "   ...\n",
      "   [0.07058824 0.05490196 0.04705882 0.07058824 0.04705882 0.05490196]\n",
      "   [0.05490196 0.03529412 0.03529412 0.0627451  0.04705882 0.04705882]\n",
      "   [0.0745098  0.05490196 0.07058824 0.05098039 0.04705882 0.04313725]]\n",
      "\n",
      "  [[0.07058824 0.0627451  0.05490196 0.06666667 0.04705882 0.0627451 ]\n",
      "   [0.0627451  0.04705882 0.04313725 0.09019608 0.07058824 0.08627451]\n",
      "   [0.07843137 0.0627451  0.05490196 0.09411765 0.08235294 0.09411765]\n",
      "   ...\n",
      "   [0.05882353 0.04313725 0.04313725 0.06666667 0.04313725 0.04313725]\n",
      "   [0.05882353 0.04313725 0.04705882 0.04705882 0.03137255 0.03137255]\n",
      "   [0.05490196 0.03529412 0.04705882 0.05882353 0.05490196 0.04705882]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.05882353 0.04313725 0.04313725 0.03921569 0.02745098 0.03921569]\n",
      "   [0.0627451  0.04705882 0.04705882 0.04705882 0.03529412 0.04705882]\n",
      "   [0.0745098  0.05882353 0.05882353 0.07058824 0.0627451  0.0745098 ]\n",
      "   ...\n",
      "   [0.16470588 0.14509804 0.16078431 0.1372549  0.09803922 0.10980392]\n",
      "   [0.07058824 0.05490196 0.07058824 0.07058824 0.03921569 0.05098039]\n",
      "   [0.05882353 0.03921569 0.0627451  0.09411765 0.0745098  0.0745098 ]]\n",
      "\n",
      "  [[0.05882353 0.04313725 0.03921569 0.0745098  0.05490196 0.07058824]\n",
      "   [0.0745098  0.05882353 0.05490196 0.09411765 0.07058824 0.08627451]\n",
      "   [0.07058824 0.05490196 0.05098039 0.06666667 0.05098039 0.06666667]\n",
      "   ...\n",
      "   [0.16862745 0.14901961 0.16470588 0.22745098 0.18039216 0.19607843]\n",
      "   [0.06666667 0.04705882 0.06666667 0.09411765 0.05882353 0.06666667]\n",
      "   [0.05490196 0.02352941 0.05490196 0.09019608 0.0627451  0.0627451 ]]\n",
      "\n",
      "  [[0.08627451 0.07058824 0.05882353 0.08627451 0.0627451  0.07843137]\n",
      "   [0.07843137 0.0627451  0.05098039 0.0745098  0.05098039 0.06666667]\n",
      "   [0.08235294 0.06666667 0.05490196 0.0627451  0.04313725 0.05882353]\n",
      "   ...\n",
      "   [0.16862745 0.14901961 0.16470588 0.25098039 0.19607843 0.21176471]\n",
      "   [0.05098039 0.03137255 0.04705882 0.06666667 0.03137255 0.03921569]\n",
      "   [0.0627451  0.03529412 0.0627451  0.05882353 0.03529412 0.02745098]]]\n",
      "\n",
      "\n",
      " [[[0.0627451  0.03921569 0.0627451  0.05098039 0.04313725 0.04705882]\n",
      "   [0.0745098  0.05490196 0.07058824 0.05098039 0.04705882 0.04313725]\n",
      "   [0.05490196 0.03529412 0.04705882 0.05882353 0.05490196 0.04705882]\n",
      "   ...\n",
      "   [0.05882353 0.03921569 0.0627451  0.09411765 0.0745098  0.0745098 ]\n",
      "   [0.05490196 0.02352941 0.05490196 0.09019608 0.0627451  0.0627451 ]\n",
      "   [0.0627451  0.03529412 0.0627451  0.05882353 0.03529412 0.02745098]]\n",
      "\n",
      "  [[0.05882353 0.03921569 0.03137255 0.07058824 0.05490196 0.05882353]\n",
      "   [0.05490196 0.03529412 0.03529412 0.0627451  0.04705882 0.04705882]\n",
      "   [0.05882353 0.04313725 0.04705882 0.04705882 0.03137255 0.03137255]\n",
      "   ...\n",
      "   [0.07058824 0.05490196 0.07058824 0.07058824 0.03921569 0.05098039]\n",
      "   [0.06666667 0.04705882 0.06666667 0.09411765 0.05882353 0.06666667]\n",
      "   [0.05098039 0.03137255 0.04705882 0.06666667 0.03137255 0.03921569]]\n",
      "\n",
      "  [[0.11372549 0.09411765 0.07843137 0.09019608 0.06666667 0.07843137]\n",
      "   [0.07058824 0.05490196 0.04705882 0.07058824 0.04705882 0.05490196]\n",
      "   [0.05882353 0.04313725 0.04313725 0.06666667 0.04313725 0.04313725]\n",
      "   ...\n",
      "   [0.16470588 0.14509804 0.16078431 0.1372549  0.09803922 0.10980392]\n",
      "   [0.16862745 0.14901961 0.16470588 0.22745098 0.18039216 0.19607843]\n",
      "   [0.16862745 0.14901961 0.16470588 0.25098039 0.19607843 0.21176471]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.05882353 0.05098039 0.04313725 0.07843137 0.05882353 0.0745098 ]\n",
      "   [0.07058824 0.05882353 0.05490196 0.05490196 0.03529412 0.05098039]\n",
      "   [0.07843137 0.0627451  0.05490196 0.09411765 0.08235294 0.09411765]\n",
      "   ...\n",
      "   [0.0745098  0.05882353 0.05882353 0.07058824 0.0627451  0.0745098 ]\n",
      "   [0.07058824 0.05490196 0.05098039 0.06666667 0.05098039 0.06666667]\n",
      "   [0.08235294 0.06666667 0.05490196 0.0627451  0.04313725 0.05882353]]\n",
      "\n",
      "  [[0.05490196 0.05098039 0.04313725 0.09411765 0.07843137 0.09411765]\n",
      "   [0.07843137 0.0745098  0.06666667 0.0627451  0.04313725 0.05882353]\n",
      "   [0.0627451  0.04705882 0.04313725 0.09019608 0.07058824 0.08627451]\n",
      "   ...\n",
      "   [0.0627451  0.04705882 0.04705882 0.04705882 0.03529412 0.04705882]\n",
      "   [0.0745098  0.05882353 0.05490196 0.09411765 0.07058824 0.08627451]\n",
      "   [0.07843137 0.0627451  0.05098039 0.0745098  0.05098039 0.06666667]]\n",
      "\n",
      "  [[0.05490196 0.05098039 0.04313725 0.0627451  0.03921569 0.05490196]\n",
      "   [0.05882353 0.05490196 0.04705882 0.05490196 0.03137255 0.04705882]\n",
      "   [0.07058824 0.0627451  0.05490196 0.06666667 0.04705882 0.0627451 ]\n",
      "   ...\n",
      "   [0.05882353 0.04313725 0.04313725 0.03921569 0.02745098 0.03921569]\n",
      "   [0.05882353 0.04313725 0.03921569 0.0745098  0.05490196 0.07058824]\n",
      "   [0.08627451 0.07058824 0.05882353 0.08627451 0.0627451  0.07843137]]]]\n"
     ]
    }
   ],
   "source": [
    "# Data augementation \n",
    "# generate more category FIVE\n",
    "\n",
    "def rotate_a_bunch(a_list_of_image):\n",
    "    res = []\n",
    "    for i in range(0, len(a_list_of_image)):\n",
    "        rotate_once1 = np.rot90(a_list_of_image[i], k=1, axes=(0, 1))\n",
    "        a = rotate_once1[::-1]\n",
    "        rotate_twice1 = np.rot90(rotate_once1, k=1, axes=(0, 1))\n",
    "        b = rotate_twice1[::-1]\n",
    "        rotate_third1 = np.rot90(rotate_twice1, k=1, axes=(0, 1))\n",
    "        c = rotate_third1[::-1]\n",
    "        rotate_once2 = np.rot90(a_list_of_image[i], k=1, axes=(1, 0))\n",
    "        d= rotate_once2[::-1]\n",
    "        rotate_twice2 = np.rot90(rotate_once2, k=1, axes=(1, 0))\n",
    "        e = rotate_twice2[::-1]\n",
    "        rotate_third2 = np.rot90(rotate_twice2, k=1, axes=(1, 0))\n",
    "        f = rotate_third2[::-1]\n",
    "        \n",
    "        new_gen = [rotate_once1,rotate_once2, rotate_twice1,rotate_twice2,rotate_third1, rotate_third2 ]\n",
    "        new_gen2 = [a,b,c,d,e,f]\n",
    "        res= new_gen + res + new_gen2\n",
    "    return np.array(res) \n",
    "\n",
    "generated_5 = rotate_a_bunch(train_is_five)\n",
    "\n",
    "print(generated_5)\n",
    "\n",
    "generated_5_label = [5] * len(generated_5)\n",
    "\n",
    "# create the new training data set (note test data set is already seperated out before hand)\n",
    "train_images = np.concatenate((train_images , generated_5)) \n",
    "train_labels =  np.concatenate((train_labels , generated_5_label)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1054\n",
      "1054\n",
      "[13  2  1 ...  5  5  5]\n"
     ]
    }
   ],
   "source": [
    "print(len(train_images))\n",
    "print(len(train_labels))\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further split training data to actual training data and validation data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_images , val_images, train1_labels , val_labels =  train_test_split(train_images, train_labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of each data set after the data augementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Training data: 843\n",
      " #Validation data: 211\n",
      " #Testing data: 225\n",
      "#Class: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"#Training data: {}\\n #Validation data: {}\\n #Testing data: {}\\n#Class: {}\".format(len(train1_images), len(val_images), len(test_images), len(set(train_labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename 1,2,5,12 category number to 0 1 2 3 \n",
    "def change_cat_number(list_1):\n",
    "    for i in range(0,len(list_1)):\n",
    "        if list_1[i] == 1:\n",
    "            list_1[i] = 0\n",
    "        elif list_1[i] == 2:\n",
    "            list_1[i] = 1\n",
    "        elif list_1[i] == 5:\n",
    "            list_1[i] = 2\n",
    "        else: \n",
    "            list_1[i] = 3\n",
    "    return list_1\n",
    "\n",
    "train1_labels = change_cat_number(train1_labels)\n",
    "val_labels= change_cat_number(val_labels)\n",
    "test_labels = change_cat_number(test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take a look at the frequency distribution of our four categories in the training data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# output the new frequency \n",
    "df = pd.DataFrame({'freq': train1_labels})\n",
    "df.groupby('freq', as_index=False).size().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at transformed labels. There should only by 0, 1,2 ,3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 1 3 1 2 2 3 0 2 1 2 1 0 3 3 1 1 0 1 1 0 3 0 1 1 1 1 3 0 3 3 0 1 3 0 0\n",
      " 3 0 2 1 1 1 3 1 2 1 0 1 0 0 1 1 1 2 1 0 1 0 3 1 2 3 0 0 3 2 3 0 0 3 3 1 1\n",
      " 3 1 0 3 3 0 1 0 1 3 1 1 0 2 1 3 0 1 3 1 1 0 0 3 1 1 0 2 0 1 1 3 0 0 1 2 0\n",
      " 1 3 1 0 3 2 0 0 1 0 3 3 0 3 0 3 2 3 2 3 0 3 0 3 3 0 3 1 1 0 1 2 0 2 1 3 0\n",
      " 3 0 1 3 0 3 3 1 0 2 2 1 2 0 2 3 0 3 0 1 3 3 3 0 3 1 0 1 1 1 1 0 0 1 1 2 1\n",
      " 3 3 1 0 1 1 1 3 0 3 1 1 0 2 0 0 0 1 0 1 1 3 1 3 0 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create model\n",
    "- https://www.tensorflow.org/tutorials/images/classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(set(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet model\n",
    "class AlexNet(Sequential):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.add(Conv2D(96, kernel_size=(11,11), strides= 4,\n",
    "                        padding= 'valid', activation= 'relu',\n",
    "                        input_shape= input_shape,\n",
    "                        kernel_initializer= 'he_normal'))\n",
    "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                              padding= 'valid', data_format= None))\n",
    "\n",
    "        self.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
    "                        padding= 'same', activation= 'relu',\n",
    "                        kernel_initializer= 'he_normal'))\n",
    "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                              padding= 'valid', data_format= None)) \n",
    "\n",
    "        self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "                        padding= 'same', activation= 'relu',\n",
    "                        kernel_initializer= 'he_normal'))\n",
    "\n",
    "        self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "                        padding= 'same', activation= 'relu',\n",
    "                        kernel_initializer= 'he_normal'))\n",
    "\n",
    "        self.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                        padding= 'same', activation= 'relu',\n",
    "                        kernel_initializer= 'he_normal'))\n",
    "\n",
    "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                              padding= 'valid', data_format= None))\n",
    "\n",
    "        #drop out at 0.4  achieve 79% accuracy in prediction \n",
    "        #drop out at 0.5 achieve 73% accuracy in prediction \n",
    "        self.add(Flatten())\n",
    "        self.add(Dense(4096, activation= 'relu'))\n",
    "        self.add(Dropout(0.3))\n",
    "        self.add(Dense(4096, activation= 'relu'))\n",
    "        self.add(Dropout(0.3))\n",
    "        self.add(Dense(1000, activation= 'relu'))\n",
    "        self.add(Dropout(0.3))\n",
    "        self.add(Dense(num_classes, activation= 'softmax'))\n",
    "\n",
    "        self.compile(optimizer= tf.keras.optimizers.Adam(0.0001),\n",
    "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet((200, 200, 6), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"alex_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 96)        69792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 23, 23, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 23, 23, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              26218496  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 4004      \n",
      "=================================================================\n",
      "Total params: 50,882,860\n",
      "Trainable params: 50,882,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some training parameters\n",
    "EPOCHS = 10\n",
    "image_height = 200\n",
    "image_width = 200\n",
    "train_dir = \"train\"\n",
    "valid_dir = \"validation\"\n",
    "model_dir = \"my_model.h5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 74s 3s/step - loss: 1.4820 - accuracy: 0.3096 - val_loss: 1.2669 - val_accuracy: 0.3697\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 71s 3s/step - loss: 1.2044 - accuracy: 0.4733 - val_loss: 1.1371 - val_accuracy: 0.4834\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 72s 3s/step - loss: 1.0722 - accuracy: 0.5208 - val_loss: 1.0860 - val_accuracy: 0.4645\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 73s 3s/step - loss: 0.9143 - accuracy: 0.6109 - val_loss: 0.9937 - val_accuracy: 0.5498\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 72s 3s/step - loss: 0.8659 - accuracy: 0.6109 - val_loss: 1.0044 - val_accuracy: 0.6019\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 73s 3s/step - loss: 0.7583 - accuracy: 0.7034 - val_loss: 0.8828 - val_accuracy: 0.6730\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 70s 3s/step - loss: 0.5533 - accuracy: 0.7912 - val_loss: 0.9398 - val_accuracy: 0.6825\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 75s 3s/step - loss: 0.5751 - accuracy: 0.7841 - val_loss: 0.8716 - val_accuracy: 0.7251\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 70s 3s/step - loss: 0.4186 - accuracy: 0.8529 - val_loss: 0.6999 - val_accuracy: 0.7962\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 73s 3s/step - loss: 0.3258 - accuracy: 0.8802 - val_loss: 1.0708 - val_accuracy: 0.7393\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "history = model.fit(train1_images, train1_labels, epochs=10, \n",
    "                    validation_data=(val_images, val_labels))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-31-0b36f4dbf883>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "# make prediction\n",
    "predicted_label = model.predict_classes(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 3 3 3 3 3 0 1 3 0 3 0 2 0 3 1 3 0 0 3 2 0 1 0 1 2 3 0 1 0 3 3 0 0 3 2\n",
      " 0 0 3 3 0 1 3 3 0 0 3 1 3 3 0 0 3 1 3 0 3 3 3 0 3 3 0 0 3 0 3 1 3 0 3 1 3\n",
      " 0 0 0 1 3 3 3 3 3 1 1 1 3 3 0 3 0 1 1 0 3 1 0 1 0 0 3 1 3 2 0 3 3 1 0 2 3\n",
      " 0 3 2 3 3 3 3 3 1 3 3 3 3 1 0 0 0 3 3 1 0 0 0 3 0 1 3 0 0 0 1 1 0 1 0 3 1\n",
      " 3 3 3 0 0 1 0 0 0 1 3 0 2 3 3 0 1 3 3 0 3 2 0 1 3 3 1 1 3 0 0 3 0 0 3 0 0\n",
      " 0 3 0 1 3 0 0 1 3 3 0 2 0 1 3 3 3 1 3 3 3 0 3 0 0 3 0 0 1 1 1 0 1 0 3 2 0\n",
      " 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[64  3  0  7]\n",
      " [13 40  1 10]\n",
      " [ 0  0  6  2]\n",
      " [ 4  0  4 71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.83        74\n",
      "           1       0.93      0.62      0.75        64\n",
      "           2       0.55      0.75      0.63         8\n",
      "           3       0.79      0.90      0.84        79\n",
      "\n",
      "    accuracy                           0.80       225\n",
      "   macro avg       0.76      0.78      0.76       225\n",
      "weighted avg       0.82      0.80      0.80       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(test_labels, predicted_label))\n",
    "print(classification_report(test_labels, predicted_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reason why accuracy doesn't further increase\n",
    "1. imbalance of trianing set \n",
    "2. learning rate too large "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 4s - loss: 0.6599 - accuracy: 0.8044\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
